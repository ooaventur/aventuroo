{
  "items": [
    {
      "slug": "adobe-research-unlocking-long-term-memory-in-video-world-models-with-state-space-models-2025-05-28",
      "title": "Adobe Research Unlocking Long-Term Memory in Video World Models with State-Space Models",
      "date": "2025-05-28",
      "cover": "assets/img/cover-fallback.jpg",
      "canonical": "https://archive.aventuroo.com/tech-ai/ai-news/adobe-research-unlocking-long-term-memory-in-video-world-models-with-state-space-models-2025-05-28/",
      "excerpt": "Video world models, which predict future frames conditioned on actions, hold immense promise for artificial intelligence, enabling agents to plan and reason in dynamic environments. Recent advancements, particularly with video diffusion models, have shown impressive capabiliti…",
      "source": "https://syncedreview.com/2025/05/28/adobe-research-unlocking-long-term-memory-in-video-world-models-with-state-space-models/"
    },
    {
      "slug": "deepseek-v3-new-paper-is-coming-unveiling-the-secrets-of-low-cost-large-model-training-through-hardware-aware-co-design-2025-05-15",
      "title": "DeepSeek-V3 New Paper is coming! Unveiling the Secrets of Low-Cost Large Model Training through Hardware-Aware Co-design",
      "date": "2025-05-15",
      "cover": "assets/img/cover-fallback.jpg",
      "canonical": "https://archive.aventuroo.com/tech-ai/ai-news/deepseek-v3-new-paper-is-coming-unveiling-the-secrets-of-low-cost-large-model-training-through-hardware-aware-co-design-2025-05-15/",
      "excerpt": "A newly released 14-page technical paper from the team behind DeepSeek-V3, with DeepSeek CEO Wenfeng Liang as a co-author, sheds light on the “Scaling Challenges and Reflections on Hardware for AI Architectures.” This follow-up to their initial technical report delves into the…",
      "source": "https://syncedreview.com/2025/05/15/deepseek-v3-new-paper-is-coming-unveiling-the-secrets-of-low-cost-large-model-training-through-hardware-aware-co-design/"
    }
  ],
  "count": 2,
  "updated_at": "2025-05-28",
  "pagination": {
    "total_items": 2,
    "per_page": 12,
    "total_pages": 1
  }
}
